#!/usr/bin/perl

use strict;
use warnings;
use Getopt::Long;
use POSIX;
use FindBin '$Bin';
use lib "$Bin/../";
use lib "$Bin/"; #Useful for ln -s to script, but need hicup_module.pm in same dir
use hicup_module;
use hicup_module qw(get_csome_position); 

use Data::Dumper;

########################################################################################
########################################################################################
## This file is Copyright (C) 2023, Steven Wingett (steven.wingett@mrc-lmb.cam.ac.uk) ##
##                                                                                    ##
##                                                                                    ##
## This file is part of HiCUP.                                                        ##
##                                                                                    ##
## HiCUP is free software: you can redistribute it and/or modify                      ##
## it under the terms of the GNU General Public License as published by               ##
## the Free Software Foundation, either version 3 of the License, or                  ##
## (at your option) any later version.                                                ##
##                                                                                    ##
## HiCUP is distributed in the hope that it will be useful,                           ##
## but WITHOUT ANY WARRANTY; without even the implied warranty of                     ##
## MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the                      ##
## GNU General Public License for more details.                                       ##
##                                                                                    ##
## You should have received a copy of the GNU General Public License                  ##
## along with HiCUP.  If not, see <http://www.gnu.org/licenses/>.                     ##
########################################################################################
########################################################################################


##########################################################
# Get user-supplied parameters
# Option variables
my %config = (
    aligned => undef,
    digest => undef,
    fastq1 => undef,
    fastq2 => undef,
    help => undef,
    version => undef,
    zip => undef
);

my $config_result = GetOptions(
    "aligned=s" => \$config{aligned},
    "digest=s" => \$config{digest},
    "fastq1=s" => \$config{fastq1},
    "fastq2=s" => \$config{fastq2},
    "help" => \$config{help},
    "version" => \$config{version},
	  "zip" => \$config{zip}
);
die "Could not parse options.\n" unless ($config_result);


if ( $config{help} ) {
    print while (<DATA>);
    exit(0);
}

if ( $config{version} ) {    #Print version and exit
    print "hicup2ncc v$hicup_module::VERSION\n";
    exit(0);
}

if(@ARGV){
    die "You have passed an argument with no option, please try again.\n";
}

##########################################################
# Check input
unless( defined $config{aligned} and defined $config{fastq1} and defined $config{fastq2}){
    die "Please specify --aligned, --fastq1, --fastq2 files.\n";
}

my @aligned_files = split(/\s/, $config{aligned});
my @fastq1_files = split(/\s/, $config{fastq1});
my @fastq2_files = split(/\s/, $config{fastq2});

# Check all of equal length
unless( (scalar @aligned_files == scalar @fastq1_files) and (scalar @aligned_files == scalar @fastq2_files ) ){
    die "The --aligned, --fastq1 and --fastq2 values must all contain the same number of files.\n";
}

unless(defined $config{digest}){
  die "Please specify the --digest file used in the HiCUP analysis.\n";
}


##########################################################
# Process Digest File

print "Processing digest file '" . $config{digest} . "'\n";

# Read in digest file to get restriction fragment positions
if ( $config{digest} =~ /\.gz$/ ) {
	open( DIGEST, "gunzip -c $config{digest} |" ) or die "Could not open '$config{digest}' : $!";
} else {
	open(DIGEST, '<', $config{digest}) or die "Could not open '$config{digest}' : $!";
}

my %fragments;    #%{chromosome}->{10kb region}->{Start} = End

scalar <DIGEST>;   #Ignore headers
scalar <DIGEST>;
while(<DIGEST>){
	my $line = $_;
	chomp $line;
  next if $line =~ /^\s*$/;    #Ignore blank lines
	my ($csome, $start, $end) = split(/\t/, $line);
	add_fragment($csome, $start, $end, \%fragments);
}
close DIGEST or die "Could not close '$config{digest}' : $!";


# Read in FASTQ files and BAM file in sets of threes
for (my $i = 0; $i < scalar @aligned_files; $i++){
  my $aligned_file = $aligned_files[$i];
  my $fastq_file1 = $fastq1_files[$i];
  my $fastq_file2 = $fastq2_files[$i];
  
  print "Processing $aligned_file with $fastq_file1 with $fastq_file2\n";

  ##########################################################
  # Process FASTQ Files
  my $first_file_flag = 1;
  my %fastq_indexes;    # %{index_id} = read_number
  foreach my $fastq_file ($fastq_file1, $fastq_file2){
    my $read_count = 0;
    print "\treading $fastq_file\n";

    my $fh_fastq = cleverOpen($fastq_file);
      while(<$fh_fastq>) {
        my $header = $_;
        chomp $header;
        ($header) = split(/\s/, $header);
        $header =~ s/^@//;   #Remove @ from header
        my $seq = scalar <$fh_fastq>;
        chomp $seq;
        scalar <$fh_fastq>;   #Rest of FASTQ read
        scalar <$fh_fastq>;

        $read_count++;

        if($first_file_flag){
          if(exists $fastq_indexes{$header}){
            warn "Header '$header' found multiple time in $fastq_file1\n";
            die "This should not happen!\n";
          } else {
            $fastq_indexes{$header} = $read_count;
          }
        
        } else {    #Second file
          if(exists $fastq_indexes{$header}){
            unless($fastq_indexes{$header} == $read_count){
              warn "Read index numbers do not match for '$header'\n";
              die "This should not happen!\n";
            }
          } else {
            warn "Header '$header' not found in $fastq_file2, but found in $fastq_file1\n";
            die "This should not happen!\n";
          }
        }
      }
    close $fh_fastq or die "Could not close filehandle on '$fastq_file' : $!";
    $first_file_flag = 0   #Second file of pair
  }

  #print Dumper \%fastq_indexes;

  print "Reading $aligned_file\n";  
  
  #Clever open
  my $fh_aligned = cleverOpen($aligned_file);  
  my $outfile = "$aligned_file.ncc";
  if($config{zip}){
	  $outfile .= '.gz';
	  open(OUT, "| gzip -c - > $outfile") or die "Could not write to '$outfile' : $!";
  }else{
	  open (OUT, '>', $outfile) or die "Could not write to '$outfile'\n";
  }
  
  ##########################################################
  # Process BAM Files
  my $index = 1;

  while(<$fh_aligned>){
    if(/^@/){    #Remove SAM header lines
      next;
    }    
    
    my $readF = $_;
    my $readR = scalar <$fh_aligned>;
    chomp $readF;
    chomp $readR;
    my @read_pair = ($readF, $readR);
    my @ditag_halves;   # @[ditag1_info, ditag2_info] - to be sorted later
    
 
    foreach my $read (@read_pair){
      my ($csome, $start, $end, $strand, $sonication_pos) = get_read_positions($read);
      my $fragment = coord2bin($csome, $sonication_pos, \%fragments);

      unless($fragment){
        warn "Could not find the following read in the restriction digest co-ordinate system:\n";
        warn "$read\n";
        die "This should not happen!\n";
      }

      my (undef, $fragment_start, $fragment_end) = split(/\t/, $fragment);
      push(@ditag_halves, [$csome, $start, $end, $fragment_start, $fragment_end, $strand]);
    }

    my $label_half_1 = join("\t", $ditag_halves[0]->[1], $ditag_halves[0]->[2], $ditag_halves[0]->[5]);
    my $label_half_2 = join("\t", $ditag_halves[1]->[1], $ditag_halves[1]->[2], $ditag_halves[0]->[1]);
    my $full_label;
    my $swap = 0;

    if ( ( $label_half_1 cmp $label_half_2 ) == 1 ) {
      $full_label = join("\t", (@{$ditag_halves[1]}, @{$ditag_halves[0]}));
      $swap = 1;
    } else {
      $full_label = join("\t", (@{$ditag_halves[0]}, @{$ditag_halves[1]}));
    }

    #print Dumper \@ditag_halves;

 
    
    #Get read position on original FASTQ file
    my ($align_headerF) = split(/\t/, $readF);
    my ($align_headerR) = split(/\t/, $readR);

    #Check headers make sense i.e. Forward is same as Reverse
    if($align_headerF eq $align_headerR){
      unless(exists $fastq_indexes{$align_headerF}){
        warn "Header '$align_headerF' in HiCUP file not found in FASTQ file\n";
        warn "Header '$align_headerR' in HiCUP file not found in FASTQ file\n";
        warn "$readF\n";
        warn "$readR\n";
        die "This should not happen!\n";
      }
    } else {
      warn "Paired headers in HiCUP file do not match:\n";
      warn "$align_headerF\n";
      warn "$align_headerR\n";
      warn "$readF\n";
      warn "$readR\n";
      die "This should not happen!\n";
    }

    my $aligned_read_index_in_fastq = $fastq_indexes{$align_headerF};   # rem: align_headerF == align_headerF
    my $ncc_data_line .= join("\t", $full_label, $index, $swap) . "\n";   #Ambiguity group same as number of reads
    print OUT $ncc_data_line;
    $index++;
  }

  close $fh_aligned or die "Could not close filehandle on '$aligned_file' : $!";
  close OUT or die "Could not close filehandle on '$outfile' : $!";
}

print "Processing complete\n";

exit(0);




###########################################################
# Subroutines - maybe add modules add_fragment and coord2bin
# to the modules files, as they are shared with get_captured_reads
# Subroutine get_read_positions is in many ways an improvement 
# on get_csome_position in the modules file
###########################################################


#####################################################################
#Subroutines
#####################################################################


#######################
##Subroutine "cleverOpen":
##Opens a file with a filhandle suitable for the file extension
sub cleverOpen{
my $file  = shift;
my $fh;

if( $file =~ /\.bam$/){
	open( $fh, "samtools view -h $file |" ) or die "Couldn't read '$file' : $!";  
}elsif ($file =~ /\.gz$/){
	open ($fh,"gunzip -c $file |") or die "Couldn't read $file : $!";
} else {
	open ($fh, $file) or die "Could not read $file: $!";
}
return $fh;
}


##########################################
#Subroutine: add_fragment
#Takes the bait chromosome/start/end
#and populates the passed hash accordingly:
#%{chromosome}->{10kb region}->{Start} = End
#Note: if the bin/fragment spans more than one 10kb region,
#then multiple 10 regions will be populated
sub add_fragment {
	my ($csome, $start, $end, $hash_ref) = @_;
	
	my $ten_kb_start = ceil($start / 10_000);
	my $ten_kb_end = ceil($end/ 10_000);
	
	for (my $ten_kb_region = $ten_kb_start; $ten_kb_region <= $ten_kb_end; $ten_kb_region++){
		${$hash_ref}{$csome}->{$ten_kb_region}->{$start} = $end;
	}
}


##########################################
#Subroutine: coord2bin
#Receives a chromosome name and a position and reference to the baits hash
#and returns the bait co-ordinates where this location is found (else returns 0)
#%lookup_hash{chromosome}->{10kb region}->{Start} = End
sub coord2bin{
	my ($csome, $pos, $hash_ref) = @_;
	my $ten_kb_region = ceil($pos / 10_000);

	foreach my $start ( keys %{ $fragments{$csome}->{$ten_kb_region} }){
		my $end = ${ $hash_ref }{$csome}->{$ten_kb_region}->{$start};
		if ( ($start <= $pos) and ($end >= $pos) ){
			return ("$csome\t$start\t$end");
		}
	}
	return 0;    #Not makking to fragment
}


####################
#Subroutine get_read_positions
#Takes a SAM read and returns the chromosome,the start, end, strand and sonication point
#positions, as aligned to the reference genome.
sub get_read_positions{
  my $read = $_[0];
  
  my $csome = (split(/\t/, $read))[2];
  my $pos = (split(/\t/, $read))[3];    #Position reported in SAM/BAM file
  my $cigar = (split(/\t/, $read))[5];
  my $strand = (split(/\t/, $read))[1];

  #Determine $genomic_length from the CIGAR string
  # for InDel free matches we can simply use the M number in the CIGAR string
  my $genomic_length = 0;    #Read length, when aligned to the reference genome
  
  if ($cigar =~ /^(\d+)M$/){ # linear match
    $genomic_length = $1;
  } else {    #Contains InDels
    # parsing CIGAR string
    my @len = split (/\D+/,$cigar); # storing the length per operation
    my @ops = split (/\d+/,$cigar); # storing the operation
    shift @ops; # remove the empty first element
    die "CIGAR string contained a non-matching number of lengths and operations ($cigar)\n" unless (scalar @len == scalar @ops);

    # warn "CIGAR string; $cigar\n";
    ### determining end position of the read
    foreach my $index(0..$#len){
      if ($ops[$index] eq 'M'){  # standard matching bases
        $genomic_length += $len[$index];
      } elsif($ops[$index] eq 'I'){ 
        # insertions do not affect the length
      } elsif($ops[$index] eq 'D'){    # deletions do affect the length             
        $genomic_length += $len[$index];
      } else {
        die "Found CIGAR operations other than M, I or D: '$ops[$index]'. Not allowed at the moment\n";
      }
    }
  }

  #Determine the start and end of the read on the genome
  my $start;
  my $end;
  my $sonication_pos;
  
  if($strand & 0x10){    #Negative strand
    $start = $pos - $genomic_length + 1;
    $end = $pos;
    $strand = '-';
    $sonication_pos = $end;
  } else {    #Positive strand
    $start = $pos;
    $end = $pos + $genomic_length - 1;
    $strand = '+';
    $sonication_pos = $start;
  }

  return($csome, $start, $end, $strand, $sonication_pos);
}


__DATA__

HiCUP homepage: www.bioinformatics.babraham.ac.uk/projects/hicup

The hicup2ncc script converts HiCUP BAM/SAM files to NCC format, which is 
generated by the NucProcess pipeline:
https://github.com/tjs23/nuc_processing/wiki/NCC-data-format

SYNOPSIS

hicup2ncc [OPTIONS]
hicup2ncc [SAM/BAM FILES]...

FUNCTION

HiCUP generates SAM/BAM files of mapped, filtered paired-end reads 
constituting the sequenced valid Hi-C di-tags. These may then be analysed by a 
variety of specialised tools, but before this is possible the datasets will 
need parsing into an appropriate format.

The hicup2ncc script converts HiCUP BAM/SAM files to NCC format compatible which 
is genetated by the NucProcess pipeline:

The columns of NCC files correspond to:

- Name of chromosome A
- First base position of sequence read A
- Last base position of sequence read A
- 5' base position of primary RE fragment containing read A
- 3' base position of primary RE fragment containing read A
- The strand of sequence read A
- Name of chromosome B
- First base position of sequence read B
- Last base position of sequence read B
- 5' base position of primary RE fragment containing read B
- 3' base position of primary RE fragment containing read B
- The strand of sequence read B
- The number of the ambiguity group to which the paired reads belong
- The ID number of the read pair in the original FASTQ files
- Whether read pairs are swapped relative to original FASTQ files

This script expects the sonication protocol to have been followed in the Hi-C 
library construction, rather than the legacy double-digest protocol.

IMPORTANT NOTE: The order of the --aligned, --fastq1 and --fastq2 files need to
correspond exactly to one another for correct processing.

COMMAND LINE OPTIONS

--aligned      Whitespace-separated list of HiCUP BAM/SAM files
--digest       HiCUP digest file used in HiCUP analysis
--fastq1       Whitespace-separated list of FASTQ (read1) files
--fastq2       Whitespace-separated list of FASTQ (read2) files
               The order of the aligned, fastq1 and fastq2 files
               should correspond to one another - you may use
               wildcards or a space-sepatated list between quotation
               marks
--help         Print help message and exit
--version      Print the program version and exit
--zip          Write output to a gzip file

Full instructions on running the pipeline can be found at:
www.bioinformatics.babraham.ac.uk/projects/hicup

Steven Wingett, The MRC Laboratory of Molecular Biology, Cambridge, UK 
(steven.wingett@mrc-lmb.cam.ac.uk)
