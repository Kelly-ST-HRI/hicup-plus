#!/usr/bin/perl

use strict;
use warnings;
use Getopt::Long;
#use File::Temp qw/ tempdir /;
use File::Path qw(remove_tree);
use File::Basename;
use Cwd 'abs_path';
use FindBin '$Bin';
use lib $Bin;
use hicup_module;
use hicup_module qw(hashVal check_no_duplicate_filename checkAligner checkAlignerIndices
  quality_checker fileNamer datestampGenerator determineAlignerFormat);

use Data::Dumper;

##########################################################
#Get user-supplied parameters
#Option variables
my %config = (
    datestamp => '',
    help      => '',
    outdir    => '',
    quiet     => '',
    version   => '',
);

my $config_result = GetOptions(    #Stores parameters
    "datestamp"  => \$config{datestamp},
    "help"       => \$config{help},
    "outdir=s"   => \$config{outdir},
    "quiet"      => \$config{quiet},
);

die "Command line options need to be in the correct format (hicup -help for more details).\n" unless ($config_result);


#Print version and exit
if ( $config{version} ) {
    print "HiCUP v$hicup_module::VERSION\n";
    exit(0);
}

unless(scalar (@ARGV) == 1){
    die "Please enter ONE folder to process.\n";
}


print "Creating combined HiCUP summary report\n";

my $indir = abs_path($ARGV[0]);
chomp $indir;

unless(-d $indir){
    warn "Input directory does not exist:\n";
    warn "'$indir'\n";
    die "Please adjust configuration.\n"
}

print "Reading folder '" . $indir . "'\n";

#Look in target folder for all the hicup_deduplicater files (the last step in the pipeline)
#Identify all the reports, grouping by the unique ids in the the summary report filenames
#Process each of these groups in termn
#Note: this is the one part of the code that does not use fileNamer in HiCUP module to determine the filenames
my @glob_results = glob($indir . '/' . "hicup_deduplicator_summary_*");    
my %groups_summaryfiles;    # %{group} = @[truncater_summary, mapper_summary, filter_summary, deduplicator_summary]
my @summary_file_types = qw(truncater mapper filter deduplicator);

#Check that all the summary files are present
foreach my $group (@glob_results){
    $group = basename($group);
    $group =~ /^hicup_deduplicator_summary_(.+)\.txt$/;
    $group = $1;

    foreach my $summary_file_type (@summary_file_types){
        my $summary_file = $indir . '/hicup_' . $summary_file_type . '_summary_' . "$group.txt";
        push( @{ $groups_summaryfiles{$group} }, $summary_file);

        unless(-e $summary_file){
            warn "Could not find expected summary file: '$summary_file'\n";
            die "Please check input files\n";
        }
    }
}

if(scalar (keys %groups_summaryfiles)){
    print "\t" . scalar (keys %groups_summaryfiles) . " complete summary results groups identified in folder\n"
} else {
    die "Could not identify any complete summary results groups in folder.\n";
}


#Write all the summary results into a datastructure
my %summary_data;    # %{summary_group} -> {summary_filename} -> @[data_line]
foreach my $summary_group (keys %groups_summaryfiles){
    foreach my $summary_file ( @{ $groups_summaryfiles{$summary_group} } ){
        my $fh_in = cleverOpen($summary_file);
        scalar <$fh_in>;    #Ignore header
        while(<$fh_in>){
            my $line = $_;
            chomp $line;
            push( @{ $summary_data{$summary_group}->{$summary_file} }, $line);
        }
        close $fh_in or die "Could not close '$summary_file' : $!";
    }
}

#print Dumper \%summary_data;

#Process each group in turn 
foreach my $summary_group (keys %summary_data){
    
    #Use the deduplicater summary file to determine the files that made it all the way throught the pipeline
    #Determine whether --zip was selected and whether samtools was used and set the dummy config datastructure accordingly
    #Don't collect the values now, but do this as we pass sequentially through all the summary files
    my($truncater_summaryfile, $mapper_summaryfile, $filter_summaryfile, $deduplicater_summaryfile) = @{ $groups_summaryfiles{$summary_group} };
    my @specimen_data = @{ $summary_data{$summary_group}->{$deduplicater_summaryfile} };
    my ($specimen_filename) = split("\t", $specimen_data[0]);

    my %config_dummy;
    if($specimen_filename =~ /\.bam$/){
        $config_dummy{samtools} = 1;
        $config_dummy{zip} = 1;
    } elsif($specimen_filename =~ /\.sam\.gz$/){
        $config_dummy{zip} = 1;
    } elsif($specimen_filename =~ /\.sam$/){    #Internal check
        #No config options to adjust
    } else {
        die "Filename extension of file '$specimen_filename' in '$deduplicater_summaryfile' not recognised.\n";
    }



    #Extract truncater summary results for all the files that passed through the pipeline.
    #File Total_Reads_1 Total_Reads_2 Not_Truncated_Reads_1 Not_Truncated_Reads_2 Truncated_Read_1 Truncated_Read_2 Average_Length_Truncated_1 Average_Length_Truncated_2 Too_Short_To_Map_Read_1 Too_Short_To_Map_Read_2 Unique_Alignments_Read_1 Unique_Alignments_Read_2 Multiple_Alignments_Read_1 Multiple_Alignments_Read_2 Failed_To_Align_Read_1 Failed_To_Align_Read_2 Paired_Read_1 Paired_Read_2 Valid_Pairs Invalid_Pairs Same_Circularised Same_Dangling_Ends Same_Fragment_Internal Re_Ligation Contiguous_Sequence Wrong_Size Deduplication_Read_Pairs_Uniques Deduplication_Cis_Close_Uniques Deduplication_Cis_Far_Uniques Deduplication_Trans_Uniques Percentage_Mapped Percentage_Valid Percentage_Uniques Percentage_Unique_Trans Percentage_Ditags_Passed_Through_HiCUP
    #File Total_Reads_1 Total_Reads_2 Not_Truncated_Reads_1 Not_Truncated_Reads_2 Truncated_Read_1 Truncated_Read_2 Average_Length_Truncated_1 Average_Length_Truncated_2 Too_Short_To_Map_Read_1 Too_Short_To_Map_Read_2 Unique_Alignments_Read_1 Unique_Alignments_Read_2 Multiple_Alignments_Read_1 Multiple_Alignments_Read_2 Failed_To_Align_Read_1 Failed_To_Align_Read_2 Paired_Read_1 Paired_Read_2 Valid_Pairs Invalid_Pairs Wrong_Size No_Ligation No_Ligation_Internal_Re2 Unclassified Unmapped Self_Ligation Deduplication_Read_Pairs_Uniques Deduplication_Cis_Close_Uniques Deduplication_Cis_Far_Uniques Deduplication_Trans_Uniques Percentage_Mapped Percentage_Valid Percentage_Uniques Percentage_Unique_Trans Percentage_Ditags_Passed_Through_HiCUP


    # Check the forward and reverse reads for a file pair correspond exactly.


    #Extract filter summary results (this could be a sonication or double-digest protocol)


}




#Write out the text summary results file.  Write a combined file and a file for each processed datastructure

#Use plot.ly to produce a summary HTML report

print "Created combined summary reports\n";

exit (0);


###################################################################################
#Subroutines
###################################################################################




#######################
##Subroutine "cleverOpen":
##Opens a file with a filhandle suitable for the file extension
sub cleverOpen{
  my $file  = shift;
  my $fh;
  
    if( $file =~ /\.bam$/){
        open( $fh, "samtools view -h $file |" ) or die "Couldn't read '$file' : $!";  
    }elsif ($file =~ /\.gz$/){
        open ($fh,"zcat $file |") or die "Couldn't read $file : $!";
    } else {
        open ($fh, $file) or die "Could not read $file: $!";
    }
  return $fh;
}




















